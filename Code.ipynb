{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import sklearn\n",
    "import random\n",
    "from random import shuffle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = glob.glob('.\\lsp_dataset\\images\\im*.jpg') \n",
    "file = open('.\\lsp_dataset\\labels.txt', 'r') \n",
    "all_labels = file.read()\n",
    "labels = all_labels.split()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_unique = list(set(labels))\n",
    "print(just_unique)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(just_unique)\n",
    "encoded_Y = encoder.transform(just_unique)\n",
    "print(encoded_Y)\n",
    "categorical = np_utils.to_categorical(encoded_Y)\n",
    "print(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_and_test_samples = train_test_split(samples, test_size=0.4)\n",
    "validation_samples, test_samples = train_test_split(validation_and_test_samples, test_size=0.5)\n",
    "\n",
    "print(len(train_samples))\n",
    "print(len(validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(samples[0]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = cv2.resize(image, (96,96))\n",
    "image = image/np.linalg.norm(image, ord=np.inf, axis=0, keepdims=True)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "                    \n",
    "number_list = list(filter(str.isdigit, samples[0]))\n",
    "number_of_label = int(number_list[0])*1000 + int(number_list[1])*100 + int(number_list[2])*10 + int(number_list[3])\n",
    "label = labels[number_of_label-1]\n",
    "print(label)\n",
    "\n",
    "translation_matrix1 = np.float32([ [1,0, random.randint(-10,10)], [0,1, random.randint(-10,10)] ])\n",
    "img_translation1 = cv2.warpAffine(image, translation_matrix1, (96, 96))\n",
    "plt.imshow(img_translation1)\n",
    "plt.show()\n",
    "                    \n",
    "img_cropping1 = cv2.resize(image[random.randint(0,5) : (95-random.randint(0,5)) , random.randint(0,5) : (95-random.randint(0,5)) ], (96,96))\n",
    "plt.imshow(img_cropping1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=20):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            priv_labels = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                images = []\n",
    "                priv_labels = []\n",
    "                for batch_sample in batch_samples:\n",
    "                    image = cv2.cvtColor(cv2.imread(batch_sample), cv2.COLOR_BGR2RGB)\n",
    "                    image = cv2.resize(image, (96,96))\n",
    "                    image = image/np.linalg.norm(image, ord=np.inf, axis=0, keepdims=True)\n",
    "                    \n",
    "                    number_list = list(filter(str.isdigit, batch_sample))\n",
    "                    number_of_label = int(number_list[0])*1000 + int(number_list[1])*100 + int(number_list[2])*10 + int(number_list[3])\n",
    "                    label = labels[number_of_label-1]\n",
    "                    \n",
    "                    translation_matrix1 = np.float32([ [1,0, random.randint(-10,10)], [0,1, random.randint(-10,10)] ])\n",
    "                    translation_matrix2 = np.float32([ [1,0, random.randint(-5,5)], [0,1, random.randint(-5,5)] ])\n",
    "                    translation_matrix3 = np.float32([ [1,0, random.randint(-8,8)], [0,1, random.randint(-8,8)] ])\n",
    "                    img_translation1 = cv2.warpAffine(image, translation_matrix1, (96, 96))\n",
    "                    img_translation2 = cv2.warpAffine(image, translation_matrix2, (96, 96))\n",
    "                    img_translation3 = cv2.warpAffine(image, translation_matrix3, (96, 96))\n",
    "                    \n",
    "                    img_cropping1 = cv2.resize(image[random.randint(0,5) : (95-random.randint(0,5)) , random.randint(0,5) : (95-random.randint(0,5)) ], (96,96))\n",
    "                    img_cropping2 = cv2.resize(image[random.randint(0,5) : (95-random.randint(0,5)) , random.randint(0,5) : (95-random.randint(0,5)) ], (96,96))\n",
    "                    img_cropping3 = cv2.resize(image[random.randint(0,5) : (95-random.randint(0,5)) , random.randint(0,5) : (95-random.randint(0,5)) ], (96,96))\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    images.append(np.fliplr(image))\n",
    "                    images.append(img_translation1)\n",
    "                    images.append(np.fliplr(img_translation1))\n",
    "                    images.append(img_translation2)\n",
    "                    images.append(np.fliplr(img_translation2))\n",
    "                    images.append(img_translation3)\n",
    "                    images.append(np.fliplr(img_translation3))\n",
    "                    images.append(img_cropping1)\n",
    "                    images.append(np.fliplr(img_cropping1))\n",
    "                    images.append(img_cropping2)\n",
    "                    images.append(np.fliplr(img_cropping2))\n",
    "                    images.append(img_cropping3)\n",
    "                    images.append(np.fliplr(img_cropping3))\n",
    "                    encoded_y = encoder.transform([label])\n",
    "                    for it in range(0,14):\n",
    "                        priv_labels.append(encoded_y)\n",
    "            X_train = np.array(images)\n",
    "            a = np_utils.to_categorical(priv_labels, nb_classes=16)\n",
    "            y_train=np.array(a)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "            \n",
    "            \n",
    "def val_generator(samples, batch_size=20):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            priv_labels = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                images = []\n",
    "                priv_labels = []\n",
    "                for batch_sample in batch_samples:\n",
    "                    image = cv2.cvtColor(cv2.imread(batch_sample), cv2.COLOR_BGR2RGB)\n",
    "                    image = cv2.resize(image, (96,96))\n",
    "                    image = image/np.linalg.norm(image, ord=np.inf, axis=0, keepdims=True)\n",
    "                    \n",
    "                    number_list = list(filter(str.isdigit, batch_sample))\n",
    "                    number_of_label = int(number_list[0])*1000 + int(number_list[1])*100 + int(number_list[2])*10 + int(number_list[3])\n",
    "                    label = labels[number_of_label-1]\n",
    "                    encoded_y = encoder.transform([label])\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    priv_labels.append(encoded_y)\n",
    "            X_train = np.array(images)\n",
    "            a = np_utils.to_categorical(priv_labels, nb_classes=16)\n",
    "            y_train=np.array(a)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_samples, batch_size=20)\n",
    "validation_generator = val_generator(validation_samples, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, Cropping2D, Reshape, Activation, BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Activation\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "model.add(Convolution2D(20, 4, 4, border_mode='same', input_shape=(96, 96, 3 )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2) ))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# second layer\n",
    "model.add(Convolution2D( 15, 3, 3, border_mode='same'))#input_shape=(3, 256, 256)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# third layer\n",
    "model.add(Convolution2D(12, 3, 3, border_mode='same'))# input_shape=(3, 256, 256)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# fourth layer\n",
    "model.add(Convolution2D(5, 2, 2 , border_mode='same'))# input_shape=(3, 256, 256)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully connected 1 with dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully connected 2 with dropout\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Softmax \n",
    "model.add(Dense(16))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], learning_rate=0.0000000000001)\n",
    "model.fit_generator(train_generator, samples_per_epoch = 14*len(train_samples), \n",
    "                    validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_last.h5')\n",
    "print(\"Model summary:\\n\", model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
